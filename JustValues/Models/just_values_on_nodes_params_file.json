{
    "learning_rate":0.0005,
    "batch_size":50,
    "dropout":0,
    "optimizer":"adam",
    "activation":"relu",
    "regularization": 1e-5,
    "layer_1":50,
    "layer_2":30,
    "train_frac":0.8,
    "runs_number": 2,
    "epochs": 2
}
