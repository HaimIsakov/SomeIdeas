{
    "learning_rate":0.01,
    "batch_size":30,
    "dropout":0.3,
    "optimizer":"adam",
    "activation":"tanh",
    "regularization": 1e-3,
    "layer_1":100,
    "layer_2":200,
    "train_frac":0.75,
    "test_frac": 0.25,
    "epochs":20,
    "initialization":"xavier"
}
