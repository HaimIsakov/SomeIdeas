{"learning_rate": 0.0019110172090220132, "batch_size": 16, "dropout": 0, "optimizer": "adam", "activation": "relu",
  "regularization": 0, "layer_1": 143.0, "layer_2": 145.0, "train_frac": 0.7, "test_frac": 0.15, "epochs": 200, "preweight": 14.0,
  "numrec": 125, "thresh": 0.2}